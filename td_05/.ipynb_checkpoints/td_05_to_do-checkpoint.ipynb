{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "597Hu82gSNCZ"
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/fr/0/0b/Polytech_Lyon_logo.png\" alt=\"drawing\" height=\"200\"/>\n",
    "\n",
    "# Traitement de donn√©es & Programmation en Python\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA-XK862WiMt"
   },
   "source": [
    "# TD 05\n",
    "\n",
    "Traitement de donn√©es\n",
    "\n",
    "![Good luck!](https://media.tenor.com/YoFWnXe4V3kAAAAd/may-the-odds-be-ever-in-your-favor-may-the-odds-hunger-games.gif)\n",
    " \n",
    "Elements √† consulter:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Doc                                   |             Link\n",
    "--------------------------------------|------------------------------------\n",
    "Github Helper      | [>link<](#scrollTo=Github_101)\n",
    "Python en 30 jours | [>link<](https://moncoachdata.com/courses/apprendre-python-en-30-jours/)\n",
    "Get started with pandas | [>link<](https://colab.research.google.com/notebooks/snippets/pandas.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1g4EgT41MqJ"
   },
   "source": [
    "## Intro\n",
    "\n",
    "Le premier bloc devrait toujours contenir les installs/imports dont on aura besoin pour le reste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjiE8c51VoT0",
    "outputId": "2f4856bd-590b-4197-a9f0-e3a020d191eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is awesome üëç\n"
     ]
    }
   ],
   "source": [
    "# Installs\n",
    "print(\"Python is awesome üëç\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JhT-50uwz72F"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsB9ADLg8i8P",
    "outputId": "162e09d0-12e6-4112-972d-91cea118215a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6]], np.int32)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKow2OZ5LCXr"
   },
   "source": [
    "### Correction TD precedent\n",
    "\n",
    "Partir d'un fichier csv et alimenter la binge watch list :\n",
    "  > serie, plateform, nb_episodes, ann√©e_sortie, note\n",
    "\n",
    "Puis print :\n",
    "\n",
    "\t Nom de la s√©rie : Brooklyn Nine-Nine\n",
    "\t Ann√©e de sortie : 2013\n",
    "\n",
    "\t Nom de la s√©rie : The office\n",
    "\t Ann√©e de sortie : 2005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lcQQFp3w0HE"
   },
   "outputs": [],
   "source": [
    "def csv_to_dict(file_path, separator=\";\", row_limit=None):\n",
    "    \"\"\"\n",
    "    Transforms a csv file, into a list of dictionaries\n",
    "\n",
    "    Arguments:\n",
    "        file_path  {str} : eg. /documents/file.txt\n",
    "        separator  {str} : separator of fields, default (;)\n",
    "        row_limit  {int} : limit the rows to be read, default None\n",
    "\n",
    "    Returns list[dict]\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        serie = {}\n",
    "        serie_list = []\n",
    "        for i, row in enumerate(f, 1):\n",
    "            if i == 1:\n",
    "                header = row.lower().strip().replace(' ','_').split(separator)\n",
    "                # print(\"\\nHeaders:\", header,\"\\n\")\n",
    "            else:\n",
    "                data = row.lower().strip().split(separator)\n",
    "                # print(\"Data:\",data)\n",
    "                if len(header) == len(data):\n",
    "                    for j, element in enumerate(header):\n",
    "                        serie[header[j]] = data[j]\n",
    "            # print(serie)\n",
    "                serie_list.append(serie)\n",
    "                serie = {}\n",
    "            if i == row_limit:\n",
    "                break\n",
    "    return serie_list\n",
    "\n",
    "\n",
    "\n",
    "file_path = \"./netflix_titles.csv\"\n",
    "# file_path = \"./tv_shows_pipe.csv\"\n",
    "limit = None\n",
    "binge_watch_list = csv_to_dict(file_path,separator=\"|\",row_limit=limit)\n",
    "# for serie in binge_watch_list:\n",
    "#   print(serie.get('title'))\n",
    "# # Option 1 read some rows to see what we have\n",
    "\n",
    "df = pd.DataFrame(binge_watch_list)\n",
    "df[\"title\"] = df[\"title\"].str.title()\n",
    "df.head(5)\n",
    "\n",
    "column_name = 'release_year'\n",
    "filter = df['release_year'] == '2005'\n",
    "# df.query(f\"`{column_name}` == '2003'\")\n",
    "df[filter]\n",
    "# # serie, plateform, nb_episodes, ann√©e_sortie, note\n",
    "# df2 = df.melt(id_vars=['title','year','imdb','rotten_tomatoes'],\n",
    "#               var_name='plateform', \n",
    "#               value_vars=['netflix','hulu','prime_video','disney+'])\n",
    "# df2.drop(['value'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2lJWv62kQZA"
   },
   "source": [
    "##EX01\n",
    "### Numpy intro\n",
    "\n",
    "* Cr√©er un vecteur depuis la liste ['Lyon', 'Paris', 'Montpellier']\n",
    "    * Assigner le r√©sultat √† la variable `villes`\n",
    "* Cr√©er une matrice depuis la liste de listes suivante: `[['Lyon', '69'], ['Paris', '75'], ['Montpellier','34']]`\n",
    "    * Assigner le r√©sultat √† la variable `villes_departement`\n",
    "* Assigner la taille du vecteur `villes` √† la variable `v_shape`\n",
    "* Assigner la taille du tableau `villes_departement` √† la variable `vd_shape` \n",
    "* Afficher les r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n_jOsgGllUhC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lyon' 'Paris' 'Montpellier']\n",
      "[['Lyon' '69']\n",
      " ['Paris' '75']\n",
      " ['Montpellier' '34']]\n",
      "(3,)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "villes = np.array(['Lyon','Paris','Montpellier'])\n",
    "villes_departement = np.array([['Lyon','69'],['Paris','75'],['Montpellier','34']])\n",
    "v_shape = villes.shape\n",
    "vd_shape = villes_departement.shape\n",
    "print(villes)\n",
    "print(villes_departement)\n",
    "print(v_shape)\n",
    "print(vd_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8WBS9oVKcWs"
   },
   "source": [
    "##EX02\n",
    "### Numpy intro\n",
    "\n",
    "#### Part 1\n",
    "\n",
    "* Telecharger le dataset [cereal.csv](https://www.kaggle.com/datasets/crawford/80-cereals?select=cereal.csv) avec les colonnes suivantes :\n",
    "\n",
    "```\n",
    "['name', 'mfr', 'type', 'calories', 'protein', 'fat', 'sodium', 'fiber',\n",
    "'carbo', 'sugars', 'potass', 'vitamins', 'shelf', 'weight', 'cups',\n",
    "'rating']\n",
    "```\n",
    "\n",
    "* Afficher les deux premieres colonnes et toute les lignes\n",
    "* Afficher la derni√®re colonne\n",
    "* Afficher les 5 premieres lignes de la 4√®me colonne\n",
    "* Assigner a une variable `corn_flakes_cals` le nombre de calories par 100 gr de c√©r√©ales de la marque Corn Flakes \n",
    "* Assigner le nom de la 3eme marque sur le dataset a une variabe `third_brand`\n",
    "* Mettre dans une liste toutes les marques de c√©reales en utilisant `.tolist()` & afficher cette derni√®re\n",
    "* Mettre les 10 premiere marques dans le fichiers dans une liste `first_ten_brands` & afficher cette derni√®re\n",
    "> bonus \n",
    "* Convertir la colonne ratings en d√©cimale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTDsqYIgpitx",
    "outputId": "d2cd6d75-cf4d-4421-c34f-097def1f3b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 16)\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "file_path = \"./cereal.csv\"\n",
    "data = np.genfromtxt(file_path,\n",
    "                     delimiter=\",\",\n",
    "                     dtype=None,\n",
    "                     encoding=None,\n",
    "                     autostrip=True,\n",
    "                     )\n",
    "data = data[1:,:]\n",
    "print(data.shape) ## retourne (lignes, colonnes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['100% Bran' 'N']\n",
      " ['100% Natural Bran' 'Q']\n",
      " ['All-Bran' 'K']\n",
      " ['All-Bran with Extra Fiber' 'K']\n",
      " ['Almond Delight' 'R']\n",
      " ['Apple Cinnamon Cheerios' 'G']\n",
      " ['Apple Jacks' 'K']\n",
      " ['Basic 4' 'G']\n",
      " ['Bran Chex' 'R']\n",
      " ['Bran Flakes' 'P']\n",
      " [\"Cap'n'Crunch\" 'Q']\n",
      " ['Cheerios' 'G']\n",
      " ['Cinnamon Toast Crunch' 'G']\n",
      " ['Clusters' 'G']\n",
      " ['Cocoa Puffs' 'G']\n",
      " ['Corn Chex' 'R']\n",
      " ['Corn Flakes' 'K']\n",
      " ['Corn Pops' 'K']\n",
      " ['Count Chocula' 'G']\n",
      " [\"Cracklin' Oat Bran\" 'K']\n",
      " ['Cream of Wheat (Quick)' 'N']\n",
      " ['Crispix' 'K']\n",
      " ['Crispy Wheat & Raisins' 'G']\n",
      " ['Double Chex' 'R']\n",
      " ['Froot Loops' 'K']\n",
      " ['Frosted Flakes' 'K']\n",
      " ['Frosted Mini-Wheats' 'K']\n",
      " ['Fruit & Fibre Dates; Walnuts; and Oats' 'P']\n",
      " ['Fruitful Bran' 'K']\n",
      " ['Fruity Pebbles' 'P']\n",
      " ['Golden Crisp' 'P']\n",
      " ['Golden Grahams' 'G']\n",
      " ['Grape Nuts Flakes' 'P']\n",
      " ['Grape-Nuts' 'P']\n",
      " ['Great Grains Pecan' 'P']\n",
      " ['Honey Graham Ohs' 'Q']\n",
      " ['Honey Nut Cheerios' 'G']\n",
      " ['Honey-comb' 'P']\n",
      " ['Just Right Crunchy  Nuggets' 'K']\n",
      " ['Just Right Fruit & Nut' 'K']\n",
      " ['Kix' 'G']\n",
      " ['Life' 'Q']\n",
      " ['Lucky Charms' 'G']\n",
      " ['Maypo' 'A']\n",
      " ['Muesli Raisins; Dates; & Almonds' 'R']\n",
      " ['Muesli Raisins; Peaches; & Pecans' 'R']\n",
      " ['Mueslix Crispy Blend' 'K']\n",
      " ['Multi-Grain Cheerios' 'G']\n",
      " ['Nut&Honey Crunch' 'K']\n",
      " ['Nutri-Grain Almond-Raisin' 'K']\n",
      " ['Nutri-grain Wheat' 'K']\n",
      " ['Oatmeal Raisin Crisp' 'G']\n",
      " ['Post Nat. Raisin Bran' 'P']\n",
      " ['Product 19' 'K']\n",
      " ['Puffed Rice' 'Q']\n",
      " ['Puffed Wheat' 'Q']\n",
      " ['Quaker Oat Squares' 'Q']\n",
      " ['Quaker Oatmeal' 'Q']\n",
      " ['Raisin Bran' 'K']\n",
      " ['Raisin Nut Bran' 'G']\n",
      " ['Raisin Squares' 'K']\n",
      " ['Rice Chex' 'R']\n",
      " ['Rice Krispies' 'K']\n",
      " ['Shredded Wheat' 'N']\n",
      " [\"Shredded Wheat 'n'Bran\" 'N']\n",
      " ['Shredded Wheat spoon size' 'N']\n",
      " ['Smacks' 'K']\n",
      " ['Special K' 'K']\n",
      " ['Strawberry Fruit Wheats' 'N']\n",
      " ['Total Corn Flakes' 'G']\n",
      " ['Total Raisin Bran' 'G']\n",
      " ['Total Whole Grain' 'G']\n",
      " ['Triples' 'G']\n",
      " ['Trix' 'G']\n",
      " ['Wheat Chex' 'R']\n",
      " ['Wheaties' 'G']\n",
      " ['Wheaties Honey Gold' 'G']]\n"
     ]
    }
   ],
   "source": [
    "#Afficher les deux premieres colonnes et toute les lignes\n",
    "print(data[:,:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['68.402973' '33.983679' '59.425505' '93.704912' '34.384843' '29.509541'\n",
      " '33.174094' '37.038562' '49.120253' '53.313813' '18.042851' '50.764999'\n",
      " '19.823573' '40.400208' '22.736446' '41.445019' '45.863324' '35.782791'\n",
      " '22.396513' '40.448772' '64.533816' '46.895644' '36.176196' '44.330856'\n",
      " '32.207582' '31.435973' '58.345141' '40.917047' '41.015492' '28.025765'\n",
      " '35.252444' '23.804043' '52.076897' '53.371007' '45.811716' '21.871292'\n",
      " '31.072217' '28.742414' '36.523683' '36.471512' '39.241114' '45.328074'\n",
      " '26.734515' '54.850917' '37.136863' '34.139765' '30.313351' '40.105965'\n",
      " '29.924285' '40.692320' '59.642837' '30.450843' '37.840594' '41.503540'\n",
      " '60.756112' '63.005645' '49.511874' '50.828392' '39.259197' '39.703400'\n",
      " '55.333142' '41.998933' '40.560159' '68.235885' '74.472949' '72.801787'\n",
      " '31.230054' '53.131324' '59.363993' '38.839746' '28.592785' '46.658844'\n",
      " '39.106174' '27.753301' '49.787445' '51.592193' '36.187559']\n"
     ]
    }
   ],
   "source": [
    "#Afficher la derni√®re colonne\n",
    "print(data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['70' '120' '70' '50' '110']\n"
     ]
    }
   ],
   "source": [
    "#Afficher les 5 premieres lignes de la 4√®me colonne\n",
    "print(data[:5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Corn Flakes' 'K' 'C' '100' '2' '0' '290' '1' '21' '2' '35' '25' '1'\n",
      "  '1' '1' '45.863324']]\n",
      "352.7336860670194\n"
     ]
    }
   ],
   "source": [
    "#Assigner a une variable corn_flakes_cals le nombre de calories par 100 gr de c√©r√©ales de la marque Corn Flakes\n",
    "#1 ounce = 28.35 grams\n",
    "CONVERSION_EN_GRAMS = 28.35\n",
    "filter = data[:,0]=='Corn Flakes'\n",
    "corn_flakes = data[filter]\n",
    "print(corn_flakes)\n",
    "cals = float(corn_flakes[0,3])\n",
    "weight = float(corn_flakes[0,13])*CONVERSION_EN_GRAMS\n",
    "corn_flakes_cals = cals*100/weight\n",
    "print(corn_flakes_cals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All-Bran\n"
     ]
    }
   ],
   "source": [
    "#Assigner le nom de la 3eme marque sur le dataset a une variabe third_brand\n",
    "third_band = data[2,0]\n",
    "print(third_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100% Bran', '100% Natural Bran', 'All-Bran', 'All-Bran with Extra Fiber', 'Almond Delight', 'Apple Cinnamon Cheerios', 'Apple Jacks', 'Basic 4', 'Bran Chex', 'Bran Flakes', \"Cap'n'Crunch\", 'Cheerios', 'Cinnamon Toast Crunch', 'Clusters', 'Cocoa Puffs', 'Corn Chex', 'Corn Flakes', 'Corn Pops', 'Count Chocula', \"Cracklin' Oat Bran\", 'Cream of Wheat (Quick)', 'Crispix', 'Crispy Wheat & Raisins', 'Double Chex', 'Froot Loops', 'Frosted Flakes', 'Frosted Mini-Wheats', 'Fruit & Fibre Dates; Walnuts; and Oats', 'Fruitful Bran', 'Fruity Pebbles', 'Golden Crisp', 'Golden Grahams', 'Grape Nuts Flakes', 'Grape-Nuts', 'Great Grains Pecan', 'Honey Graham Ohs', 'Honey Nut Cheerios', 'Honey-comb', 'Just Right Crunchy  Nuggets', 'Just Right Fruit & Nut', 'Kix', 'Life', 'Lucky Charms', 'Maypo', 'Muesli Raisins; Dates; & Almonds', 'Muesli Raisins; Peaches; & Pecans', 'Mueslix Crispy Blend', 'Multi-Grain Cheerios', 'Nut&Honey Crunch', 'Nutri-Grain Almond-Raisin', 'Nutri-grain Wheat', 'Oatmeal Raisin Crisp', 'Post Nat. Raisin Bran', 'Product 19', 'Puffed Rice', 'Puffed Wheat', 'Quaker Oat Squares', 'Quaker Oatmeal', 'Raisin Bran', 'Raisin Nut Bran', 'Raisin Squares', 'Rice Chex', 'Rice Krispies', 'Shredded Wheat', \"Shredded Wheat 'n'Bran\", 'Shredded Wheat spoon size', 'Smacks', 'Special K', 'Strawberry Fruit Wheats', 'Total Corn Flakes', 'Total Raisin Bran', 'Total Whole Grain', 'Triples', 'Trix', 'Wheat Chex', 'Wheaties', 'Wheaties Honey Gold']\n"
     ]
    }
   ],
   "source": [
    "#Mettre dans une liste toutes les marques de c√©reales en utilisant .tolist() & afficher cette derni√®re\n",
    "brands = data[:,0].tolist()\n",
    "print(brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100% Bran', '100% Natural Bran', 'All-Bran', 'All-Bran with Extra Fiber', 'Almond Delight', 'Apple Cinnamon Cheerios', 'Apple Jacks', 'Basic 4', 'Bran Chex', 'Bran Flakes']\n"
     ]
    }
   ],
   "source": [
    "#Mettre les 10 premiere marques dans le fichiers dans une liste first_ten_brands & afficher cette derni√®re\n",
    "first_ten_brands = brands[:10]\n",
    "print(first_ten_brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.402973, 33.983679, 59.425505, 93.704912, 34.384843, 29.509541,\n",
       "       33.174094, 37.038562, 49.120253, 53.313813, 18.042851, 50.764999,\n",
       "       19.823573, 40.400208, 22.736446, 41.445019, 45.863324, 35.782791,\n",
       "       22.396513, 40.448772, 64.533816, 46.895644, 36.176196, 44.330856,\n",
       "       32.207582, 31.435973, 58.345141, 40.917047, 41.015492, 28.025765,\n",
       "       35.252444, 23.804043, 52.076897, 53.371007, 45.811716, 21.871292,\n",
       "       31.072217, 28.742414, 36.523683, 36.471512, 39.241114, 45.328074,\n",
       "       26.734515, 54.850917, 37.136863, 34.139765, 30.313351, 40.105965,\n",
       "       29.924285, 40.69232 , 59.642837, 30.450843, 37.840594, 41.50354 ,\n",
       "       60.756112, 63.005645, 49.511874, 50.828392, 39.259197, 39.7034  ,\n",
       "       55.333142, 41.998933, 40.560159, 68.235885, 74.472949, 72.801787,\n",
       "       31.230054, 53.131324, 59.363993, 38.839746, 28.592785, 46.658844,\n",
       "       39.106174, 27.753301, 49.787445, 51.592193, 36.187559])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertir la colonne ratings en d√©cimale\n",
    "data[:,-1].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BaW1VvWXCS7"
   },
   "source": [
    "#### Part 2\n",
    "\n",
    "* **Extraire** la premiere colonne du dataset et **la comparer** √† la valeur `'Special K'` Assigner le resultat √† une variable `special_k`\n",
    "* Executer la commande `print(data[special_k])`\n",
    "> bonus\n",
    "* Faire la meme chose mais le filtre verifie que le manufacturer est Quaker Oats (lire la doc du dataset üòâ)\n",
    "> bonus ¬≤\n",
    "* Print le nom des marques dont le fabricant est `Quaker Oats` et qui contiennent **moins** de `10 grammes` de sucre par portion\n",
    "* Ajouter une marque de c√©r√©ales \"healthy\" avec 0 grammes de sucre au dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GuXFyhUepnMc",
    "outputId": "6ec9c05d-a76c-4d8f-8c48-6285d32b6953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Special K' 'K' 'C' '110' '6' '0' '230' '1' '16' '3' '55' '25' '1' '1'\n",
      "  '1' '53.131324']]\n",
      "['100% Natural Bran' 'Life' 'Puffed Rice' 'Puffed Wheat'\n",
      " 'Quaker Oat Squares' 'Quaker Oatmeal']\n"
     ]
    }
   ],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Special K' 'K' 'C' '110' '6' '0' '230' '1' '16' '3' '55' '25' '1' '1'\n",
      "  '1' '53.131324']]\n",
      "[['100% Natural Bran' 'Q' 'C' '120' '3' '5' '15' '2' '8' '8' '135' '0'\n",
      "  '3' '1' '1' '33.983679']\n",
      " [\"Cap'n'Crunch\" 'Q' 'C' '120' '1' '2' '220' '0' '12' '12' '35' '25' '2'\n",
      "  '1' '0.75' '18.042851']\n",
      " ['Honey Graham Ohs' 'Q' 'C' '120' '1' '2' '220' '1' '12' '11' '45' '25'\n",
      "  '2' '1' '1' '21.871292']\n",
      " ['Life' 'Q' 'C' '100' '4' '2' '150' '2' '12' '6' '95' '25' '2' '1'\n",
      "  '0.67' '45.328074']\n",
      " ['Puffed Rice' 'Q' 'C' '50' '1' '0' '0' '0' '13' '0' '15' '0' '3' '0.5'\n",
      "  '1' '60.756112']\n",
      " ['Puffed Wheat' 'Q' 'C' '50' '2' '0' '0' '1' '10' '0' '50' '0' '3' '0.5'\n",
      "  '1' '63.005645']\n",
      " ['Quaker Oat Squares' 'Q' 'C' '100' '4' '1' '135' '2' '14' '6' '110'\n",
      "  '25' '3' '1' '0.5' '49.511874']\n",
      " ['Quaker Oatmeal' 'Q' 'H' '100' '5' '2' '0' '2.7' '-1' '-1' '110' '0'\n",
      "  '1' '1' '0.67' '50.828392']]\n",
      "['100% Natural Bran' 'Life' 'Puffed Rice' 'Puffed Wheat'\n",
      " 'Quaker Oat Squares' 'Quaker Oatmeal']\n"
     ]
    }
   ],
   "source": [
    "special_k = data[:,0] == 'Special K'\n",
    "print(data[special_k])         \n",
    "quaker_oats = data[:,1] == 'Q'\n",
    "print(data[quaker_oats])\n",
    "#* Print le nom des marques dont le fabricant est `Quaker Oats` et qui contiennent **moins** de `10 grammes` de sucre par portion\n",
    "filter = np.logical_and(quaker_oats,data[:,9].astype(int) <10)\n",
    "print(data[filter][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[['healthy' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0' '0.0'\n",
      "  '0.0' '0.0' '0.0' '0.0' '0.0']]\n",
      "['healthy' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0' '0.0' '0.0'\n",
      " '0.0' '0.0' '0.0' '0.0']\n"
     ]
    }
   ],
   "source": [
    "#* Ajouter une marque de c√©r√©ales \"healthy\" avec 0 grammes de sucre au dataset \n",
    "new_brand = np.zeros([1,16])\n",
    "print(new_brand)\n",
    "new_brand = new_brand.astype(str)\n",
    "new_brand[0,0] = \"healthy\"\n",
    "new_brand[0,9] = \"0\"\n",
    "print(new_brand)\n",
    "data = np.append(data,new_brand,axis=0)\n",
    "print(data[-1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdsY64gl_0dw"
   },
   "source": [
    "#### Part 3\n",
    "\n",
    "Sur le m√™me dataset, √† l'aide d'une boucle `for`:\n",
    "\n",
    "\n",
    "*   Cr√©er un dictionnaire avec la moyenne de sucre par Fabricant de c√©rales\n",
    "*   Trouver la marque de c√©reales qui contient le plus de sucre par portion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjbTgYNbCaIj",
    "outputId": "5ab1f623-f8df-45f2-e82b-7031da73f3f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['100% Bran', 'Nabisco', 'C', ..., '1', '0.33', '68.402973'],\n",
       "       ['100% Natural Bran', 'Quaker Oats', 'C', ..., '1', '1',\n",
       "        '33.983679'],\n",
       "       ['All-Bran', 'Kelloggs', 'C', ..., '1', '0.33', '59.425505'],\n",
       "       ...,\n",
       "       ['Wheat Chex', 'Ralston Purina', 'C', ..., '1', '0.67',\n",
       "        '49.787445'],\n",
       "       ['Wheaties', 'General Mills', 'C', ..., '1', '1', '51.592193'],\n",
       "       ['Wheaties Honey Gold', 'General Mills', 'C', ..., '1', '0.75',\n",
       "        '36.187559']], dtype='<U75')"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1wjqra3_yZo",
    "outputId": "ea12a660-30c6-45d0-e066-c7f4848eb455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ralston Purina': 6.125, 'Nabisco': 1.8333333333333333, 'General Mills': 7.954545454545454, 'Kelloggs': 7.565217391304348, 'American Home Food Products': 3.0, 'Post': 8.777777777777779, 'Quaker Oats': 5.25}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'American Home Food Products': 3.0, 'General Mills': 7.954545454545454, 'Kelloggs': 7.565217391304348, 'Nabisco': 1.8333333333333333, 'Post': 8.777777777777779, 'Quaker Oats': 5.25, 'Ralston Purina': 6.125}\n"
     ]
    }
   ],
   "source": [
    "#Cr√©er un dictionnaire avec la moyenne de sucre par Fabricant de c√©rales\n",
    "fabricants = [ ('A','American Home Food Products'),('G','General Mills'),('K','Kelloggs'),('N','Nabisco'),('P','Post')\n",
    "              ,('Q','Quaker Oats'),('R','Ralston Purina')]\n",
    "dict_moyenne_sucre = {}\n",
    "for fab in fabricants :\n",
    "    #filtrer uniquement manufracturer (mfr) = initial dans la liste fabricants\n",
    "    filter = data[:,1] == fab[0]\n",
    "    #r√©cup√©rer la colonne sugars du dataset et la transformer en int√©ger\n",
    "    sucres = data[filter][:,9].astype(int)\n",
    "    moyenne_sucre = sucres.mean()\n",
    "    dict_moyenne_sucre[fab[1]] = moyenne_sucre\n",
    "\n",
    "print(dict_moyenne_sucre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Golden Crisp' 'Smacks']\n"
     ]
    }
   ],
   "source": [
    "#Trouver la marque de c√©reales qui contient le plus de sucre par portion\n",
    "#Extraire la colonne sugars du dataset et la tranformer en int√©ger\n",
    "sucres = data[:,9].astype(int)\n",
    "#trouver la maximumm nombre de sucres\n",
    "max_sucres = sucres.max()\n",
    "#filtrer les marques qui ont la quantit√© de sucres √©gale √† max_sucres\n",
    "filter = data[:,9].astype(int) == max_sucres\n",
    "array_max_sucres = data[filter]\n",
    "print(array_max_sucres[:,0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHsrGdy-5AZK"
   },
   "source": [
    "## EX03\n",
    "### Dataframes\n",
    "\n",
    "Refaire l'exo du TD 4 (fichier des series) en utilisant la librairie NumPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "jIatRWhm5Xzo",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tv_shows2.csv\n",
    "from random import randint\n",
    "#filepath = \"./tv_shows2.csv\" \n",
    "def read_csv_numpy(filepath,separator) :\n",
    "    liste_series=[]\n",
    "    series = np.genfromtxt(filepath,\n",
    "                           delimiter=separator,\n",
    "                           names=True,\n",
    "                           dtype=None,\n",
    "                           encoding=None,\n",
    "                           invalid_raise=False,\n",
    "                           )\n",
    "    heads = series.dtype.names\n",
    "    for serie in series:\n",
    "        dict_serie ={}\n",
    "        dict_serie['Title'] = serie['Title']\n",
    "        plateforme = []\n",
    "        for i in range(6,10) :\n",
    "            if serie[i] == 1 :\n",
    "                plateforme.append(heads[i])\n",
    "                \n",
    "        dict_serie['plateforme'] = plateforme\n",
    "        nb_episodes = randint(6,30)\n",
    "        dict_serie['nb_episodes'] = nb_episodes\n",
    "        dict_serie['ann√©e_sortie'] = serie['Year']\n",
    "        note = serie['IMDb'].split('/')\n",
    "        try :\n",
    "            note[0] = float(note[0])\n",
    "        except :\n",
    "            pass\n",
    "        dict_serie['note'] = note[0]\n",
    "        liste_series.append(dict_serie)\n",
    "    \n",
    "    return liste_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'Breaking Bad', 'plateforme': ['Netflix'], 'nb_episodes': 7, 'ann√©e_sortie': 2008, 'note': 9.4} \n",
      "\n",
      "{'Title': 'Stranger Things', 'plateforme': ['Netflix'], 'nb_episodes': 22, 'ann√©e_sortie': 2016, 'note': 8.7} \n",
      "\n",
      "{'Title': 'Attack on Titan', 'plateforme': ['Netflix', 'Hulu'], 'nb_episodes': 11, 'ann√©e_sortie': 2013, 'note': 9.0} \n",
      "\n",
      "{'Title': 'Better Call Saul', 'plateforme': ['Netflix'], 'nb_episodes': 8, 'ann√©e_sortie': 2015, 'note': 8.8} \n",
      "\n",
      "{'Title': 'Dark', 'plateforme': ['Netflix'], 'nb_episodes': 15, 'ann√©e_sortie': 2017, 'note': 8.8} \n",
      "\n",
      "{'Title': 'Avatar: The Last Airbender', 'plateforme': ['Netflix', 'Prime_Video'], 'nb_episodes': 14, 'ann√©e_sortie': 2005, 'note': 9.3} \n",
      "\n",
      "{'Title': 'Peaky Blinders', 'plateforme': ['Netflix'], 'nb_episodes': 21, 'ann√©e_sortie': 2013, 'note': 8.8} \n",
      "\n",
      "{'Title': 'The Walking Dead', 'plateforme': ['Netflix'], 'nb_episodes': 12, 'ann√©e_sortie': 2010, 'note': 8.2} \n",
      "\n",
      "{'Title': 'Black Mirror', 'plateforme': ['Netflix'], 'nb_episodes': 13, 'ann√©e_sortie': 2011, 'note': 8.8} \n",
      "\n",
      "{'Title': \"The Queen's Gambit\", 'plateforme': ['Netflix'], 'nb_episodes': 29, 'ann√©e_sortie': 2020, 'note': 8.6} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malas\\AppData\\Local\\Temp/ipykernel_10288/1128862373.py:6: ConversionWarning: Some errors were detected !\n",
      "    Line #893 (got 2 columns instead of 11)\n",
      "    Line #3370 (got 2 columns instead of 11)\n",
      "    Line #3425 (got 12 columns instead of 11)\n",
      "    Line #3447 (got 12 columns instead of 11)\n",
      "    Line #4301 (got 2 columns instead of 11)\n",
      "    Line #4463 (got 2 columns instead of 11)\n",
      "  series = np.genfromtxt(filepath,\n"
     ]
    }
   ],
   "source": [
    "liste_series = read_csv_numpy(\"./tv_shows.csv\",\"|\")\n",
    "for i in range(10) :\n",
    "    print(liste_series[i],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94-12vgPXG10"
   },
   "source": [
    "## Github 101\n",
    "\n",
    "```shell\n",
    "# Repartir sur une nouvelle branche\n",
    "git checkout main\n",
    "# Mettre √† jour notre branche locale\n",
    "git pull origin main\n",
    "# Recr√©er une branche pour le TD 05\n",
    "git checkout -b branch_name_td05\n",
    "# Dupliquer le fichier du td et rajouter en suffix son nom\n",
    "cd 'chemin/m1-miage/'\n",
    "cp 'src/to_do/td_05/td_05.ipynb' 'src/done/td_05/td_05_nom_prenom.ipynb'\n",
    "# Faire le travail necessaire sur votre fichier et commit et push\n",
    "git add 'src/done/td_05/td_05_nom_prenom.ipynb'\n",
    "git commit -m 'message descriptif du travail fait'\n",
    "git push --set-upstream origin nom_branche\n",
    "# Faire une pull request\n",
    "```\n",
    "\n",
    "[>>>PULL REQUEST<<<](https://github.com/lapointe05/m1-miage/pulls)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "597Hu82gSNCZ",
    "k2lJWv62kQZA",
    "94-12vgPXG10"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
