{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "597Hu82gSNCZ",
        "94-12vgPXG10"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lapointe05/m1-miage/blob/manel_kalloud_td05/td_05_manel_kalloud_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "597Hu82gSNCZ"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/fr/0/0b/Polytech_Lyon_logo.png\" alt=\"drawing\" height=\"200\"/>\n",
        "\n",
        "# Traitement de donn√©es & Programmation en Python\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TD 05\n",
        "\n",
        "Traitement de donn√©es\n",
        "\n",
        "![Good luck!](https://media.tenor.com/YoFWnXe4V3kAAAAd/may-the-odds-be-ever-in-your-favor-may-the-odds-hunger-games.gif)\n",
        " \n",
        "Elements √† consulter:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Doc                                   |             Link\n",
        "--------------------------------------|------------------------------------\n",
        "Github Helper      | [>link<](#scrollTo=Github_101)\n",
        "Python en 30 jours | [>link<](https://moncoachdata.com/courses/apprendre-python-en-30-jours/)\n",
        "Get started with pandas | [>link<](https://colab.research.google.com/notebooks/snippets/pandas.ipynb)"
      ],
      "metadata": {
        "id": "EA-XK862WiMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intro\n",
        "\n",
        "Le premier bloc devrait toujours contenir les installs/imports dont on aura besoin pour le reste"
      ],
      "metadata": {
        "id": "Y1g4EgT41MqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs\n",
        "print(\"Python is awesome üëç\")"
      ],
      "metadata": {
        "id": "yjiE8c51VoT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f4856bd-590b-4197-a9f0-e3a020d191eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python is awesome üëç\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import json\n",
        "from random import randint\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JhT-50uwz72F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2, 3], [4, 5, 6]], np.int32)\n",
        "\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsB9ADLg8i8P",
        "outputId": "162e09d0-12e6-4112-972d-91cea118215a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correction TD precedent\n",
        "\n",
        "Partir d'un fichier csv et alimenter la binge watch list :\n",
        "  > serie, plateform, nb_episodes, ann√©e_sortie, note\n",
        "\n",
        "Puis print :\n",
        "\n",
        "\t Nom de la s√©rie : Brooklyn Nine-Nine\n",
        "\t Ann√©e de sortie : 2013\n",
        "\n",
        "\t Nom de la s√©rie : The office\n",
        "\t Ann√©e de sortie : 2005\n"
      ],
      "metadata": {
        "id": "iKow2OZ5LCXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csv_to_dict(file_path, separator=\";\", row_limit=None):\n",
        "    \"\"\"\n",
        "    Transforms a csv file, into a list of dictionaries\n",
        "\n",
        "    Arguments:\n",
        "        file_path  {str} : eg. /documents/file.txt\n",
        "        separator  {str} : separator of fields, default (;)\n",
        "        row_limit  {int} : limit the rows to be read, default None\n",
        "\n",
        "    Returns list[dict]\n",
        "    \"\"\"\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        serie = {}\n",
        "        serie_list = []\n",
        "        for i, row in enumerate(f, 1):\n",
        "            if i == 1:\n",
        "                header = row.lower().strip().replace(' ','_').split(separator)\n",
        "                # print(\"\\nHeaders:\", header,\"\\n\")\n",
        "            else:\n",
        "                data = row.lower().strip().split(separator)\n",
        "                # print(\"Data:\",data)\n",
        "                if len(header) == len(data):\n",
        "                    for j, element in enumerate(header):\n",
        "                        serie[header[j]] = data[j]\n",
        "            # print(serie)\n",
        "                serie_list.append(serie)\n",
        "                serie = {}\n",
        "            if i == row_limit:\n",
        "                break\n",
        "    return serie_list\n",
        "\n",
        "\n",
        "\n",
        "file_path = \"./netflix_titles.csv\"\n",
        "# file_path = \"./tv_shows_pipe.csv\"\n",
        "limit = None\n",
        "binge_watch_list = csv_to_dict(file_path,separator=\"|\",row_limit=limit)\n",
        "# for serie in binge_watch_list:\n",
        "#   print(serie.get('title'))\n",
        "# # Option 1 read some rows to see what we have\n",
        "\n",
        "df = pd.DataFrame(binge_watch_list)\n",
        "df[\"title\"] = df[\"title\"].str.title()\n",
        "df.head(5)\n",
        "\n",
        "column_name = 'release_year'\n",
        "filter = df['release_year'] == '2005'\n",
        "# df.query(f\"`{column_name}` == '2003'\")\n",
        "df[filter]\n",
        "# # serie, plateform, nb_episodes, ann√©e_sortie, note\n",
        "# df2 = df.melt(id_vars=['title','year','imdb','rotten_tomatoes'],\n",
        "#               var_name='plateform', \n",
        "#               value_vars=['netflix','hulu','prime_video','disney+'])\n",
        "# df2.drop(['value'], axis=1)"
      ],
      "metadata": {
        "id": "9lcQQFp3w0HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EX01\n",
        "### Numpy intro\n",
        "\n",
        "* Cr√©er un vecteur depuis la liste ['Lyon', 'Paris', 'Montpellier']\n",
        "    * Assigner le r√©sultat √† la variable `villes`\n",
        "* Cr√©er une matrice depuis la liste de listes suivante: `[['Lyon', '69'], ['Paris', '75'], ['Montpellier','34']]`\n",
        "    * Assigner le r√©sultat √† la variable `villes_departement`\n",
        "* Assigner la taille du vecteur `villes` √† la variable `v_shape`\n",
        "* Assigner la taille du tableau `villes_departement` √† la variable `vd_shape` \n",
        "* Afficher les r√©sultats"
      ],
      "metadata": {
        "id": "k2lJWv62kQZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Liste\n",
        "liste=['Lyon', 'Paris', 'Montpellier']\n",
        "#print(type(liste))\n",
        "\n",
        "# List to vecteur\n",
        "villes = np.array(liste)\n",
        "print(villes)\n",
        "\n",
        "# Matrice\n",
        "villes_departement = np.array([['Lyon', '69'], ['Paris', '75'], ['Montpellier','34']])\n",
        "#print(type(villes_departement))\n",
        "print(villes_departement)\n",
        "\n",
        "#taille vecteur villes\n",
        "v_shape = villes.shape\n",
        "print(v_shape)\n",
        "\n",
        "#taille matrice villes_departement\n",
        "vd_shape = villes_departement.shape\n",
        "print(vd_shape)\n"
      ],
      "metadata": {
        "id": "n_jOsgGllUhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629e322c-1572-4df3-cc2a-8a7d75aadf5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Lyon' 'Paris' 'Montpellier']\n",
            "[['Lyon' '69']\n",
            " ['Paris' '75']\n",
            " ['Montpellier' '34']]\n",
            "(3,)\n",
            "(3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EX02\n",
        "### Numpy intro\n",
        "\n",
        "#### Part 1\n",
        "\n",
        "* Telecharger le dataset [cereal.csv](https://www.kaggle.com/datasets/crawford/80-cereals?select=cereal.csv) avec les colonnes suivantes :\n",
        "\n",
        "```\n",
        "['name', 'mfr', 'type', 'calories', 'protein', 'fat', 'sodium', 'fiber',\n",
        "'carbo', 'sugars', 'potass', 'vitamins', 'shelf', 'weight', 'cups',\n",
        "'rating']\n",
        "```\n",
        "\n",
        "* Afficher les deux premieres colonnes et toute les lignes\n",
        "* Afficher la derni√®re colonne\n",
        "* Afficher les 5 premieres lignes de la 4√®me colonne\n",
        "* Assigner a une variable `corn_flakes_cals` le nombre de calories par 100 gr de c√©r√©ales de la marque Corn Flakes \n",
        "* Assigner le nom de la 3eme marque sur le dataset a une variabe `third_brand`\n",
        "* Mettre dans une liste toutes les marques de c√©reales en utilisant `.tolist()` & afficher cette derni√®re\n",
        "* Mettre les 10 premiere marques dans le fichiers dans une liste `first_ten_brands` & afficher cette derni√®re\n",
        "> bonus \n",
        "* Convertir la colonne ratings en d√©cimale"
      ],
      "metadata": {
        "id": "Q8WBS9oVKcWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#\n",
        "file_path = \"./cereal.csv\"\n",
        "data = np.genfromtxt(file_path,dtype='str', delimiter=',', autostrip=True, skip_header=1, max_rows=50)\n",
        "# print(data)\n",
        "\n",
        "#selectionne les 2 premieres colonnes (ctrl / pour comm, ctrl Entree pour run)\n",
        "col2e = data[:,:2]\n",
        "print(\"2 premieres colonnes\",col2e)\n",
        "# print(data.shape) ## retourne (lignes, colonnes)\n",
        "\n",
        "#Affiche 5e lignes et 4e colonne\n",
        "l5e_col4 = data[:5,4]\n",
        "print(\"5 premi√®res lignes et 4e colonne: \",l5e_col4)\n",
        "print(data.shape) ## retourne (lignes, colonnes)\n",
        "\n",
        "#Assigner a une variable corn_flakes_cals le nombre de calories par 100 gr de c√©r√©ales de la marque Corn Flakes\n",
        "\n",
        "corn_flakes = (data[:,0] == 'Corn Flakes')\n",
        "# print(corn_flakes)\n",
        "\n",
        "corn_flakes_cals = data[corn_flakes,3]\n",
        "print(corn_flakes_cals)\n",
        "\n",
        "# Assigner le nom de la 3eme marque sur le dataset a une variabe third_brand\n",
        "\n",
        "third_brand = data[2,0]\n",
        "print(third_brand)\n",
        "\n",
        "#Mettre dans une liste toutes les marques de c√©reales en utilisant .tolist() & afficher cette derni√®re\n",
        "\n",
        "brand_list = data[:,0].tolist()\n",
        "print(\"Liste des marques: \",brand_list)\n",
        "\n",
        "#Mettre les 10 premiere marques dans le fichiers dans une liste first_ten_brands & afficher cette derni√®re\n",
        "\n",
        "first_ten_brands = data[:10,0].tolist()\n",
        "print(\"Liste des 10 premi√®res marques: \",first_ten_brands)\n",
        "\n",
        "# Convertir la colonne ratings en d√©cimale\n",
        "\n",
        "rating_float = data[:,-1].astype(float)#pas de guillemets\n",
        "print(\"Conversion d√©cimale:\", rating_float)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTDsqYIgpitx",
        "outputId": "1762af6c-467c-4c4d-dba9-6ed14fbad7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 premi√®res lignes et 4e colonne:  ['4' '3' '4' '4' '2']\n",
            "(50, 16)\n",
            "['100']\n",
            "All-Bran\n",
            "Liste des marques:  ['100% Bran', '100% Natural Bran', 'All-Bran', 'All-Bran with Extra Fiber', 'Almond Delight', 'Apple Cinnamon Cheerios', 'Apple Jacks', 'Basic 4', 'Bran Chex', 'Bran Flakes', \"Cap'n'Crunch\", 'Cheerios', 'Cinnamon Toast Crunch', 'Clusters', 'Cocoa Puffs', 'Corn Chex', 'Corn Flakes', 'Corn Pops', 'Count Chocula', \"Cracklin' Oat Bran\", 'Cream of Wheat (Quick)', 'Crispix', 'Crispy Wheat & Raisins', 'Double Chex', 'Froot Loops', 'Frosted Flakes', 'Frosted Mini-Wheats', 'Fruit & Fibre Dates; Walnuts; and Oats', 'Fruitful Bran', 'Fruity Pebbles', 'Golden Crisp', 'Golden Grahams', 'Grape Nuts Flakes', 'Grape-Nuts', 'Great Grains Pecan', 'Honey Graham Ohs', 'Honey Nut Cheerios', 'Honey-comb', 'Just Right Crunchy  Nuggets', 'Just Right Fruit & Nut', 'Kix', 'Life', 'Lucky Charms', 'Maypo', 'Muesli Raisins; Dates; & Almonds', 'Muesli Raisins; Peaches; & Pecans', 'Mueslix Crispy Blend', 'Multi-Grain Cheerios', 'Nut&Honey Crunch', 'Nutri-Grain Almond-Raisin']\n",
            "Liste des 10 premi√®res marques:  ['100% Bran', '100% Natural Bran', 'All-Bran', 'All-Bran with Extra Fiber', 'Almond Delight', 'Apple Cinnamon Cheerios', 'Apple Jacks', 'Basic 4', 'Bran Chex', 'Bran Flakes']\n",
            "[68.402973 33.983679 59.425505 93.704912 34.384843 29.509541 33.174094\n",
            " 37.038562 49.120253 53.313813 18.042851 50.764999 19.823573 40.400208\n",
            " 22.736446 41.445019 45.863324 35.782791 22.396513 40.448772 64.533816\n",
            " 46.895644 36.176196 44.330856 32.207582 31.435973 58.345141 40.917047\n",
            " 41.015492 28.025765 35.252444 23.804043 52.076897 53.371007 45.811716\n",
            " 21.871292 31.072217 28.742414 36.523683 36.471512 39.241114 45.328074\n",
            " 26.734515 54.850917 37.136863 34.139765 30.313351 40.105965 29.924285\n",
            " 40.69232 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 2\n",
        "\n",
        "* **Extraire** la premiere colonne du dataset et **la comparer** √† la valeur `'Special K'` Assigner le resultat √† une variable `special_k`\n",
        "* Executer la commande `print(data[special_k])`\n",
        "> bonus\n",
        "* Faire la meme chose mais le filtre verifie que le manufacturer est Quaker Oats (lire la doc du dataset üòâ)\n",
        "> bonus ¬≤\n",
        "* Print le nom des marques dont le fabricant est `Quaker Oats` et qui contiennent **moins** de `10 grammes` de sucre par portion\n",
        "* Ajouter une marque de c√©r√©ales \"healthy\" avec 0 grammes de sucre au dataset "
      ],
      "metadata": {
        "id": "8BaW1VvWXCS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# data access\n",
        "file_path = \"./cereal.csv\"\n",
        "data = np.genfromtxt(file_path,dtype='str', delimiter=',', autostrip=True, skip_header=1)\n",
        "\n",
        "# Extraire la premiere colonne du dataset et la comparer √† la valeur 'Special K' Assigner le resultat √† une variable special_k\n",
        "special_k = (data[:,0] == 'Special K')\n",
        "# print(special_k)\n",
        "print(\"Special K cereal\",data[special_k])\n",
        "print(\"-------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "#Faire la meme chose mais le filtre verifie que le manufacturer est Quaker Oats\n",
        "quaker_oats = (data[:,1] == 'Q')\n",
        "print(\"Manufacturier Quaker Oats\",data[quaker_oats])\n",
        "print(\"-------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "# Print le nom des marques dont le fabricant est Quaker Oats et qui contiennent moins de 10 grammes de sucre par portion\n",
        "quaker_oats_cals = data[quaker_oats,9]\n",
        "print(\"Liste des calories: \",quaker_oats_cals)\n",
        "quaker_oats_cals_10 = list(filter(lambda i: True if i < 10 else False, (data[quaker_oats,9]).astype(int)))\n",
        "print(\"Calories inferieur √† 10: \",quaker_oats_cals_10)\n",
        "brand_quaker_oats_cals_10 = data[quaker_oats_cals_10,0]\n",
        "print(\"Cereales avec - de 10 calories fabriqu√©es par Quaker Oats: \",brand_quaker_oats_cals_10)\n",
        "\n",
        "\n",
        "# Print le nom des marques dont le fabricant est Quaker Oats et qui contiennent moins de 10 grammes de sucre par portion\n",
        "healthy_cereal = np.array(['Healthy cereal','R','C','50','3','1','35','11','5','0','135','25','3','3','0.33','23.174094'])\n",
        "data = np.r_[data,[healthy_cereal]]\n",
        "# print(data)\n",
        "healthy_cereal_brand = (data[:,0] == 'Healthy cereal')\n",
        "print(\"Nouvelle marque: \",data[healthy_cereal_brand])\n",
        "\n",
        "healthy_cereal_sugar = (data[healthy_cereal_brand,9] )\n",
        "print(\"Sucre: \",healthy_cereal_sugar)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuXFyhUepnMc",
        "outputId": "0303f9e2-2962-4fad-9a22-b8be157c5c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Special K cereal [['Special K' 'K' 'C' '110' '6' '0' '230' '1' '16' '3' '55' '25' '1' '1'\n",
            "  '1' '53.131324']]\n",
            "-------------------------------------------------------------------------------------------------------\n",
            "Manufacturier Quaker Oats [['100% Natural Bran' 'Q' 'C' '120' '3' '5' '15' '2' '8' '8' '135' '0'\n",
            "  '3' '1' '1' '33.983679']\n",
            " [\"Cap'n'Crunch\" 'Q' 'C' '120' '1' '2' '220' '0' '12' '12' '35' '25' '2'\n",
            "  '1' '0.75' '18.042851']\n",
            " ['Honey Graham Ohs' 'Q' 'C' '120' '1' '2' '220' '1' '12' '11' '45' '25'\n",
            "  '2' '1' '1' '21.871292']\n",
            " ['Life' 'Q' 'C' '100' '4' '2' '150' '2' '12' '6' '95' '25' '2' '1'\n",
            "  '0.67' '45.328074']\n",
            " ['Puffed Rice' 'Q' 'C' '50' '1' '0' '0' '0' '13' '0' '15' '0' '3' '0.5'\n",
            "  '1' '60.756112']\n",
            " ['Puffed Wheat' 'Q' 'C' '50' '2' '0' '0' '1' '10' '0' '50' '0' '3' '0.5'\n",
            "  '1' '63.005645']\n",
            " ['Quaker Oat Squares' 'Q' 'C' '100' '4' '1' '135' '2' '14' '6' '110'\n",
            "  '25' '3' '1' '0.5' '49.511874']\n",
            " ['Quaker Oatmeal' 'Q' 'H' '100' '5' '2' '0' '2.7' '-1' '-1' '110' '0'\n",
            "  '1' '1' '0.67' '50.828392']]\n",
            "-------------------------------------------------------------------------------------------------------\n",
            "Liste des calories:  ['8' '12' '11' '6' '0' '0' '6' '-1']\n",
            "Calories inferieur √† 10:  [8, 6, 0, 0, 6, -1]\n",
            "Cereales avec - de 10 calories fabriqu√©es par Quaker Oats:  ['Bran Chex' 'Apple Jacks' '100% Bran' '100% Bran' 'Apple Jacks'\n",
            " 'Wheaties Honey Gold']\n",
            "Nouvelle marque:  [['Healthy cereal' 'R' 'C' '50' '3' '1' '35' '11' '5' '0' '135' '25' '3'\n",
            "  '3' '0.33' '23.174094']]\n",
            "Sucre:  ['0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 3\n",
        "\n",
        "Sur le m√™me dataset, √† l'aide d'une boucle `for`:\n",
        "\n",
        "\n",
        "*   Cr√©er un dictionnaire avec la moyenne de sucre par Fabricant de c√©rales\n",
        "*   Trouver la marque de c√©reales qui contient le plus de sucre par portion\n",
        "\n"
      ],
      "metadata": {
        "id": "NdsY64gl_0dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------- ce n'est pas la bonne solution, c'est du bricolage (mais ca fonctionne) ---------------------------\n",
        "import numpy as np\n",
        "\n",
        "file_path = \"./cereal.csv\"\n",
        "data = np.genfromtxt(file_path,dtype='str', delimiter=',', autostrip=True, skip_header=1)\n",
        "\n",
        "#remplace les acronymes des fabricants par leur nom\n",
        "a = (data[:,1] =='A')\n",
        "data[a,1] = 'American Home Food Products'\n",
        "g = (data[:,1] =='G')\n",
        "data[g,1] = 'General Mills'\n",
        "q = (data[:,1] =='Q')\n",
        "data[q,1] = 'Quaker Oats'\n",
        "n = (data[:,1] =='N')\n",
        "data[n,1] = 'Nabisco'\n",
        "p = (data[:,1] =='P')\n",
        "data[p,1] = 'Post'\n",
        "r = (data[:,1] =='R')\n",
        "data[r,1] = 'Ralston Purina'\n",
        "k = (data[:,1] =='K')\n",
        "data[k,1] = 'Kelloggs'\n",
        "  \n",
        "\n",
        "#Tri selon fabricant\n",
        "data = data[data[:,1].argsort()]\n",
        "data_fab = np.split(data[:,9].astype(float), np.unique(data[:, 1], return_index=True)[1][1:])\n",
        "#print(data)\n",
        "\n",
        "#dictionnaire vide, cl√© = fabricant et valeur = moyenne sucre\n",
        "dic = {}\n",
        "liste_fabricants =[]\n",
        "liste_fabricants_sans_doublons = []\n",
        "\n",
        "for fab in data:\n",
        "  liste_fabricants.append(fab[1])\n",
        "\n",
        "for f in liste_fabricants:\n",
        "  if f not in liste_fabricants_sans_doublons:\n",
        "    liste_fabricants_sans_doublons.append(f)\n",
        "\n",
        "#print(sans_doublons)\n",
        "\n",
        "liste_sucre = []\n",
        "for sucre in data_fab:\n",
        "  moyenne = sucre.mean()\n",
        "  liste_sucre.append(moyenne)\n",
        "#print(liste_sucre)\n",
        "  \n",
        "resultat = dict(zip(liste_fabricants_sans_doublons, liste_sucre))\n",
        "\n",
        "print(resultat)\n",
        "  \n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------\n",
        "# #question: \n",
        "#\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjbTgYNbCaIj",
        "outputId": "89cf9565-4cb7-40c3-856f-9f3697c3eaf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'American Home Food Products': 3.0, 'General Mills': 7.954545454545454, 'Kelloggs': 7.565217391304348, 'Nabisco': 1.8333333333333333, 'Post': 8.777777777777779, 'Quaker Oats': 5.25, 'Ralston Purina': 6.125}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moyenne sucre par manufacturier"
      ],
      "metadata": {
        "id": "aCmlIQ-9sLaa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1wjqra3_yZo",
        "outputId": "ea12a660-30c6-45d0-e066-c7f4848eb455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Ralston Purina': 6.125, 'Nabisco': 1.8333333333333333, 'General Mills': 7.954545454545454, 'Kelloggs': 7.565217391304348, 'American Home Food Products': 3.0, 'Post': 8.777777777777779, 'Quaker Oats': 5.25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EX03\n",
        "### Dataframes\n",
        "\n",
        "Refaire l'exo du TD 4 (fichier des series) en utilisant la librairie NumPy.\n"
      ],
      "metadata": {
        "id": "SHsrGdy-5AZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "file_path = \"./netflix_titles.csv\"\n",
        "stream = np.genfromtxt(file_path, dtype=\"str\", delimiter=';', autostrip=True, skip_header=1,max_rows=10)\n",
        "print(stream)\n",
        "\n",
        "#logique de l'exo ...\n",
        "\n",
        "#supprimer tout les espaces\n",
        "\n",
        "#d√©couper entre les , et sans compter celles qui sont entre \"\" (\",\") = Regex ?\n",
        "\n",
        "#peut travailler avec np, 2 dim avec ligne et colonne \n",
        "\n",
        "#filtre sur tvshow\n",
        "\n",
        "#selectionne les colonnes souhait√©es\n",
        "\n",
        "#insertion dans une liste que l'on va transformer en dictionnaire\n",
        "\n",
        "\n",
        "#bon d√©coupage\n",
        "# >>x=\"Titanium Dioxide (CI 77897), Black 2 (CI 77266), Iron Oxides (CI 77491, 77492, 77499), Ultramarines (CI 77007)\"\n",
        "# >> re.findall(\"[^()]*\\([^()]*\\),?\",x)\n",
        "# ['Titanium Dioxide (CI 77897),', ' Black 2 (CI 77266),', ' Iron Oxides (CI 77491, 77492, 77499),', ' Ultramarines (CI 77007)']\n",
        "\n"
      ],
      "metadata": {
        "id": "jIatRWhm5Xzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f3f128-3643-4e6d-b0e7-76b03d860f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s1,Movie,Dick Johnson Is Dead,Kirsten Johnson,,United States,\"September 25, 2021\",2020,PG-13,90 min,Documentaries,\"As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.\"'\n",
            " 's2,TV Show,Blood & Water,,\"Ama Qamata, Khosi Ngema, Gail Mabalane, Thabang Molaba, Dillon Windvogel, Natasha Thahane, Arno Greeff, Xolile Tshabalala, Getmore Sithole, Cindy Mahlangu, Ryle De Morny, Greteli Fincham, Sello Maake Ka-Ncube, Odwa Gwanya, Mekaila Mathys, Sandi Schultz, Duane Williams, Shamilla Miller, Patrick Mofokeng\",South Africa,\"September 24, 2021\",2021,TV-MA,2 Seasons,\"International TV Shows, TV Dramas, TV Mysteries\",\"After crossing paths at a party, a Cape Town teen sets out to prove whether a private-school swimming star is her sister who was abducted at birth.\"'\n",
            " 's3,TV Show,Ganglands,Julien Leclercq,\"Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabiha Akkari, Sofia Lesaffre, Salim Kechiouche, Noureddine Farihi, Geert Van Rampelberg, Bakary Diombera\",,\"September 24, 2021\",2021,TV-MA,1 Season,\"Crime TV Shows, International TV Shows, TV Action & Adventure\",\"To protect his family from a powerful drug lord, skilled thief Mehdi and his expert team of robbers are pulled into a violent and deadly turf war.\"'\n",
            " 's4,TV Show,Jailbirds New Orleans,,,,\"September 24, 2021\",2021,TV-MA,1 Season,\"Docuseries, Reality TV\",\"Feuds, flirtations and toilet talk go down among the incarcerated women at the Orleans Justice Center in New Orleans on this gritty reality series.\"'\n",
            " 's5,TV Show,Kota Factory,,\"Mayur More, Jitendra Kumar, Ranjan Raj, Alam Khan, Ahsaas Channa, Revathi Pillai, Urvi Singh, Arun Kumar\",India,\"September 24, 2021\",2021,TV-MA,2 Seasons,\"International TV Shows, Romantic TV Shows, TV Comedies\",\"In a city of coaching centers known to train India‚Äôs finest collegiate minds, an earnest but unexceptional student and his friends navigate campus life.\"'\n",
            " 's6,TV Show,Midnight Mass,Mike Flanagan,\"Kate Siegel, Zach Gilford, Hamish Linklater, Henry Thomas, Kristin Lehman, Samantha Sloyan, Igby Rigney, Rahul Kohli, Annarah Cymone, Annabeth Gish, Alex Essoe, Rahul Abburi, Matt Biedel, Michael Trucco, Crystal Balint, Louis Oliver\",,\"September 24, 2021\",2021,TV-MA,1 Season,\"TV Dramas, TV Horror, TV Mysteries\",\"The arrival of a charismatic young priest brings glorious miracles, ominous mysteries and renewed religious fervor to a dying town desperate to believe.\"'\n",
            " 's7,Movie,My Little Pony: A New Generation,\"Robert Cullen, Jos√© Luis Ucha\",\"Vanessa Hudgens, Kimiko Glenn, James Marsden, Sofia Carson, Liza Koshy, Ken Jeong, Elizabeth Perkins, Jane Krakowski, Michael McKean, Phil LaMarr\",,\"September 24, 2021\",2021,PG,91 min,Children & Family Movies,\"Equestria\\'s divided. But a bright-eyed hero believes Earth Ponies, Pegasi and Unicorns should be pals ‚Äî and, hoof to heart, she‚Äôs determined to prove it.\"'\n",
            " 's8,Movie,Sankofa,Haile Gerima,\"Kofi Ghanaba, Oyafunmike Ogunlano, Alexandra Duah, Nick Medley, Mutabaruka, Afemo Omilami, Reggie Carter, Mzuri\",\"United States, Ghana, Burkina Faso, United Kingdom, Germany, Ethiopia\",\"September 24, 2021\",1993,TV-MA,125 min,\"Dramas, Independent Movies, International Movies\",\"On a photo shoot in Ghana, an American model slips back in time, becomes enslaved on a plantation and bears witness to the agony of her ancestral past.\"'\n",
            " 's9,TV Show,The Great British Baking Show,Andy Devonshire,\"Mel Giedroyc, Sue Perkins, Mary Berry, Paul Hollywood\",United Kingdom,\"September 24, 2021\",2021,TV-14,9 Seasons,\"British TV Shows, Reality TV\",\"A talented batch of amateur bakers face off in a 10-week competition, whipping up their best dishes in the hopes of being named the U.K.\\'s best.\"'\n",
            " 's10,Movie,The Starling,Theodore Melfi,\"Melissa McCarthy, Chris O\\'Dowd, Kevin Kline, Timothy Olyphant, Daveed Diggs, Skyler Gisondo, Laura Harrier, Rosalind Chao, Kimberly Quinn, Loretta Devine, Ravi Kapoor\",United States,\"September 24, 2021\",2021,PG-13,104 min,\"Comedies, Dramas\",A woman adjusting to life after a loss contends with a feisty bird that\\'s taken over her garden ‚Äî and a husband who\\'s struggling to find a way forward.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Github 101\n",
        "\n",
        "```shell\n",
        "# Repartir sur une nouvelle branche\n",
        "git checkout main\n",
        "# Mettre √† jour notre branche locale\n",
        "git pull origin main\n",
        "# Recr√©er une branche pour le TD 05\n",
        "git checkout -b branch_name_td05\n",
        "# Dupliquer le fichier du td et rajouter en suffix son nom\n",
        "cd 'chemin/m1-miage/'\n",
        "cp 'src/to_do/td_05/td_05.ipynb' 'src/done/td_05/td_05_nom_prenom.ipynb'\n",
        "# Faire le travail necessaire sur votre fichier et commit et push\n",
        "git add 'src/done/td_05/td_05_nom_prenom.ipynb'\n",
        "git commit -m 'message descriptif du travail fait'\n",
        "git push --set-upstream origin nom_branche\n",
        "# Faire une pull request\n",
        "```\n",
        "\n",
        "[>>>PULL REQUEST<<<](https://github.com/lapointe05/m1-miage/pulls)\n"
      ],
      "metadata": {
        "id": "94-12vgPXG10"
      }
    }
  ]
}