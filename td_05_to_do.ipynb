{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "597Hu82gSNCZ"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/fr/0/0b/Polytech_Lyon_logo.png\" alt=\"drawing\" height=\"200\"/>\n",
        "\n",
        "# Traitement de donn√©es & Programmation en Python\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA-XK862WiMt"
      },
      "source": [
        "# TD 05\n",
        "\n",
        "Traitement de donn√©es\n",
        "\n",
        "![Good luck!](https://media.tenor.com/YoFWnXe4V3kAAAAd/may-the-odds-be-ever-in-your-favor-may-the-odds-hunger-games.gif)\n",
        " \n",
        "Elements √† consulter:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Doc                                   |             Link\n",
        "--------------------------------------|------------------------------------\n",
        "Github Helper      | [>link<](#scrollTo=Github_101)\n",
        "Python en 30 jours | [>link<](https://moncoachdata.com/courses/apprendre-python-en-30-jours/)\n",
        "Get started with pandas | [>link<](https://colab.research.google.com/notebooks/snippets/pandas.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1g4EgT41MqJ"
      },
      "source": [
        "## Intro\n",
        "\n",
        "Le premier bloc devrait toujours contenir les installs/imports dont on aura besoin pour le reste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjiE8c51VoT0",
        "outputId": "2f4856bd-590b-4197-a9f0-e3a020d191eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python is awesome üëç\n"
          ]
        }
      ],
      "source": [
        "# Installs\n",
        "print(\"Python is awesome üëç\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 399,
      "metadata": {
        "id": "JhT-50uwz72F"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import json\n",
        "from random import randint\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsB9ADLg8i8P",
        "outputId": "162e09d0-12e6-4112-972d-91cea118215a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([[1, 2, 3], [4, 5, 6]], np.int32)\n",
        "\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKow2OZ5LCXr"
      },
      "source": [
        "### Correction TD precedent\n",
        "\n",
        "Partir d'un fichier csv et alimenter la binge watch list :\n",
        "  > serie, plateform, nb_episodes, ann√©e_sortie, note\n",
        "\n",
        "Puis print :\n",
        "\n",
        "\t Nom de la s√©rie : Brooklyn Nine-Nine\n",
        "\t Ann√©e de sortie : 2013\n",
        "\n",
        "\t Nom de la s√©rie : The office\n",
        "\t Ann√©e de sortie : 2005\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {
        "id": "9lcQQFp3w0HE"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/mm/jpthq4lj1jx203520_pjb5q00000gn/T/ipykernel_26534/3429322884.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# # Option 1 read some rows to see what we have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinge_watch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "def csv_to_dict(file_path, separator=\";\", row_limit=None):\n",
        "    \"\"\"\n",
        "    Transforms a csv file, into a list of dictionaries\n",
        "\n",
        "    Arguments:\n",
        "        file_path  {str} : eg. /documents/file.txt\n",
        "        separator  {str} : separator of fields, default (;)\n",
        "        row_limit  {int} : limit the rows to be read, default None\n",
        "\n",
        "    Returns list[dict]\n",
        "    \"\"\"\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        serie = {}\n",
        "        serie_list = []\n",
        "        for i, row in enumerate(f, 1):\n",
        "            if i == 1:\n",
        "                header = row.lower().strip().replace(' ','_').split(separator)\n",
        "                # print(\"\\nHeaders:\", header,\"\\n\")\n",
        "            else:\n",
        "                data = row.lower().strip().split(separator)\n",
        "                # print(\"Data:\",data)\n",
        "                if len(header) == len(data):\n",
        "                    for j, element in enumerate(header):\n",
        "                        serie[header[j]] = data[j]\n",
        "            # print(serie)\n",
        "                serie_list.append(serie)\n",
        "                serie = {}\n",
        "            if i == row_limit:\n",
        "                break\n",
        "    return serie_list\n",
        "\n",
        "\n",
        "\n",
        "file_path = \"./netflix_titles-2.csv\"\n",
        "# file_path = \"./tv_shows_pipe.csv\"\n",
        "limit = None\n",
        "binge_watch_list = csv_to_dict(file_path,separator=\"|\",row_limit=limit)\n",
        "# for serie in binge_watch_list:\n",
        "#   print(serie.get('title'))\n",
        "# # Option 1 read some rows to see what we have\n",
        "\n",
        "df = pd.DataFrame(binge_watch_list)\n",
        "df[\"title\"] = df[\"title\"].str.title()\n",
        "df.head(5)\n",
        "\n",
        "column_name = 'release_year'\n",
        "filter = df['release_year'] == '2005'\n",
        "# df.query(f\"`{column_name}` == '2003'\")\n",
        "df[filter]\n",
        "# # serie, plateform, nb_episodes, ann√©e_sortie, note\n",
        "# df2 = df.melt(id_vars=['title','year','imdb','rotten_tomatoes'],\n",
        "#               var_name='plateform', \n",
        "#               value_vars=['netflix','hulu','prime_video','disney+'])\n",
        "# df2.drop(['value'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2lJWv62kQZA"
      },
      "source": [
        "##EX01\n",
        "### Numpy intro\n",
        "\n",
        "* Cr√©er un vecteur depuis la liste ['Lyon', 'Paris', 'Montpellier']\n",
        "    * Assigner le r√©sultat √† la variable `villes`\n",
        "* Cr√©er une matrice depuis la liste de listes suivante: `[['Lyon', '69'], ['Paris', '75'], ['Montpellier','34']]`\n",
        "    * Assigner le r√©sultat √† la variable `villes_departement`\n",
        "* Assigner la taille du vecteur `villes` √† la variable `v_shape`\n",
        "* Assigner la taille du tableau `villes_departement` √† la variable `vd_shape` \n",
        "* Afficher les r√©sultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "n_jOsgGllUhC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Lyon' 'Paris' 'Montpellier']\n",
            "[['Lyon' '69']\n",
            " ['Paris' '75']\n",
            " ['Montpellier' '34']]\n",
            "3\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "villes = np.array(['Lyon','Paris','Montpellier'])\n",
        "print(villes)\n",
        "villes_departement = np.array([['Lyon','69'],['Paris','75'],['Montpellier','34']])\n",
        "print(villes_departement)\n",
        "v_shape = len(villes)\n",
        "print(v_shape)\n",
        "vd_shape = len(villes_departement)\n",
        "print(vd_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8WBS9oVKcWs"
      },
      "source": [
        "##EX02\n",
        "### Numpy intro\n",
        "\n",
        "#### Part 1\n",
        "\n",
        "* Telecharger le dataset [cereal.csv](https://www.kaggle.com/datasets/crawford/80-cereals?select=cereal.csv) avec les colonnes suivantes :\n",
        "\n",
        "```\n",
        "['name', 'mfr', 'type', 'calories', 'protein', 'fat', 'sodium', 'fiber',\n",
        "'carbo', 'sugars', 'potass', 'vitamins', 'shelf', 'weight', 'cups',\n",
        "'rating']\n",
        "```\n",
        "\n",
        "* Afficher les deux premieres colonnes et toute les lignes\n",
        "* Afficher la derni√®re colonne\n",
        "* Afficher les 5 premieres lignes de la 4√®me colonne\n",
        "* Assigner a une variable `corn_flakes_cals` le nombre de calories par 100 gr de c√©r√©ales de la marque Corn Flakes \n",
        "* Assigner le nom de la 3eme marque sur le dataset a une variabe `third_brand`\n",
        "* Mettre dans une liste toutes les marques de c√©reales en utilisant `.tolist()` & afficher cette derni√®re\n",
        "* Mettre les 10 premiere marques dans le fichiers dans une liste `first_ten_brands` & afficher cette derni√®re\n",
        "> bonus \n",
        "* Convertir la colonne ratings en d√©cimale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTDsqYIgpitx",
        "outputId": "d2cd6d75-cf4d-4421-c34f-097def1f3b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['name' 'mfr' 'type' ... 'weight' 'cups' 'rating']\n",
            " ['100% Bran' 'N' 'C' ... '1' '0.33' '68.402973']\n",
            " ['100% Natural Bran' 'Q' 'C' ... '1' '1' '33.983679']\n",
            " ...\n",
            " ['Wheat Chex' 'R' 'C' ... '1' '0.67' '49.787445']\n",
            " ['Wheaties' 'G' 'C' ... '1' '1' '51.592193']\n",
            " ['Wheaties Honey Gold' 'G' 'C' ... '1' '0.75' '36.187559']]\n",
            "Les deux premi√®res colonnes et toutes les lignes sont :[['name' 'mfr']\n",
            " ['100% Bran' 'N']\n",
            " ['100% Natural Bran' 'Q']\n",
            " ['All-Bran' 'K']\n",
            " ['All-Bran with Extra Fiber' 'K']\n",
            " ['Almond Delight' 'R']\n",
            " ['Apple Cinnamon Cheerios' 'G']\n",
            " ['Apple Jacks' 'K']\n",
            " ['Basic 4' 'G']\n",
            " ['Bran Chex' 'R']\n",
            " ['Bran Flakes' 'P']\n",
            " [\"Cap'n'Crunch\" 'Q']\n",
            " ['Cheerios' 'G']\n",
            " ['Cinnamon Toast Crunch' 'G']\n",
            " ['Clusters' 'G']\n",
            " ['Cocoa Puffs' 'G']\n",
            " ['Corn Chex' 'R']\n",
            " ['Corn Flakes' 'K']\n",
            " ['Corn Pops' 'K']\n",
            " ['Count Chocula' 'G']\n",
            " [\"Cracklin' Oat Bran\" 'K']\n",
            " ['Cream of Wheat (Quick)' 'N']\n",
            " ['Crispix' 'K']\n",
            " ['Crispy Wheat & Raisins' 'G']\n",
            " ['Double Chex' 'R']\n",
            " ['Froot Loops' 'K']\n",
            " ['Frosted Flakes' 'K']\n",
            " ['Frosted Mini-Wheats' 'K']\n",
            " ['Fruit & Fibre Dates; Walnuts; and Oats' 'P']\n",
            " ['Fruitful Bran' 'K']\n",
            " ['Fruity Pebbles' 'P']\n",
            " ['Golden Crisp' 'P']\n",
            " ['Golden Grahams' 'G']\n",
            " ['Grape Nuts Flakes' 'P']\n",
            " ['Grape-Nuts' 'P']\n",
            " ['Great Grains Pecan' 'P']\n",
            " ['Honey Graham Ohs' 'Q']\n",
            " ['Honey Nut Cheerios' 'G']\n",
            " ['Honey-comb' 'P']\n",
            " ['Just Right Crunchy  Nuggets' 'K']\n",
            " ['Just Right Fruit & Nut' 'K']\n",
            " ['Kix' 'G']\n",
            " ['Life' 'Q']\n",
            " ['Lucky Charms' 'G']\n",
            " ['Maypo' 'A']\n",
            " ['Muesli Raisins; Dates; & Almonds' 'R']\n",
            " ['Muesli Raisins; Peaches; & Pecans' 'R']\n",
            " ['Mueslix Crispy Blend' 'K']\n",
            " ['Multi-Grain Cheerios' 'G']\n",
            " ['Nut&Honey Crunch' 'K']\n",
            " ['Nutri-Grain Almond-Raisin' 'K']\n",
            " ['Nutri-grain Wheat' 'K']\n",
            " ['Oatmeal Raisin Crisp' 'G']\n",
            " ['Post Nat. Raisin Bran' 'P']\n",
            " ['Product 19' 'K']\n",
            " ['Puffed Rice' 'Q']\n",
            " ['Puffed Wheat' 'Q']\n",
            " ['Quaker Oat Squares' 'Q']\n",
            " ['Quaker Oatmeal' 'Q']\n",
            " ['Raisin Bran' 'K']\n",
            " ['Raisin Nut Bran' 'G']\n",
            " ['Raisin Squares' 'K']\n",
            " ['Rice Chex' 'R']\n",
            " ['Rice Krispies' 'K']\n",
            " ['Shredded Wheat' 'N']\n",
            " [\"Shredded Wheat 'n'Bran\" 'N']\n",
            " ['Shredded Wheat spoon size' 'N']\n",
            " ['Smacks' 'K']\n",
            " ['Special K' 'K']\n",
            " ['Strawberry Fruit Wheats' 'N']\n",
            " ['Total Corn Flakes' 'G']\n",
            " ['Total Raisin Bran' 'G']\n",
            " ['Total Whole Grain' 'G']\n",
            " ['Triples' 'G']\n",
            " ['Trix' 'G']\n",
            " ['Wheat Chex' 'R']\n",
            " ['Wheaties' 'G']\n",
            " ['Wheaties Honey Gold' 'G']]\n",
            "la derni√®re colonne est  : ['rating' '68.402973' '33.983679' '59.425505' '93.704912' '34.384843'\n",
            " '29.509541' '33.174094' '37.038562' '49.120253' '53.313813' '18.042851'\n",
            " '50.764999' '19.823573' '40.400208' '22.736446' '41.445019' '45.863324'\n",
            " '35.782791' '22.396513' '40.448772' '64.533816' '46.895644' '36.176196'\n",
            " '44.330856' '32.207582' '31.435973' '58.345141' '40.917047' '41.015492'\n",
            " '28.025765' '35.252444' '23.804043' '52.076897' '53.371007' '45.811716'\n",
            " '21.871292' '31.072217' '28.742414' '36.523683' '36.471512' '39.241114'\n",
            " '45.328074' '26.734515' '54.850917' '37.136863' '34.139765' '30.313351'\n",
            " '40.105965' '29.924285' '40.692320' '59.642837' '30.450843' '37.840594'\n",
            " '41.503540' '60.756112' '63.005645' '49.511874' '50.828392' '39.259197'\n",
            " '39.703400' '55.333142' '41.998933' '40.560159' '68.235885' '74.472949'\n",
            " '72.801787' '31.230054' '53.131324' '59.363993' '38.839746' '28.592785'\n",
            " '46.658844' '39.106174' '27.753301' '49.787445' '51.592193' '36.187559']\n",
            "Les deux premi√®res lignes de la 4√®me colonne : ['calories' '70']\n",
            "['100']\n",
            "All-Bran\n",
            "['name', '100% Bran', '100% Natural Bran', 'All-Bran', 'All-Bran with Extra Fiber', 'Almond Delight', 'Apple Cinnamon Cheerios', 'Apple Jacks', 'Basic 4', 'Bran Chex', 'Bran Flakes', \"Cap'n'Crunch\", 'Cheerios', 'Cinnamon Toast Crunch', 'Clusters', 'Cocoa Puffs', 'Corn Chex', 'Corn Flakes', 'Corn Pops', 'Count Chocula', \"Cracklin' Oat Bran\", 'Cream of Wheat (Quick)', 'Crispix', 'Crispy Wheat & Raisins', 'Double Chex', 'Froot Loops', 'Frosted Flakes', 'Frosted Mini-Wheats', 'Fruit & Fibre Dates; Walnuts; and Oats', 'Fruitful Bran', 'Fruity Pebbles', 'Golden Crisp', 'Golden Grahams', 'Grape Nuts Flakes', 'Grape-Nuts', 'Great Grains Pecan', 'Honey Graham Ohs', 'Honey Nut Cheerios', 'Honey-comb', 'Just Right Crunchy  Nuggets', 'Just Right Fruit & Nut', 'Kix', 'Life', 'Lucky Charms', 'Maypo', 'Muesli Raisins; Dates; & Almonds', 'Muesli Raisins; Peaches; & Pecans', 'Mueslix Crispy Blend', 'Multi-Grain Cheerios', 'Nut&Honey Crunch', 'Nutri-Grain Almond-Raisin', 'Nutri-grain Wheat', 'Oatmeal Raisin Crisp', 'Post Nat. Raisin Bran', 'Product 19', 'Puffed Rice', 'Puffed Wheat', 'Quaker Oat Squares', 'Quaker Oatmeal', 'Raisin Bran', 'Raisin Nut Bran', 'Raisin Squares', 'Rice Chex', 'Rice Krispies', 'Shredded Wheat', \"Shredded Wheat 'n'Bran\", 'Shredded Wheat spoon size', 'Smacks', 'Special K', 'Strawberry Fruit Wheats', 'Total Corn Flakes', 'Total Raisin Bran', 'Total Whole Grain', 'Triples', 'Trix', 'Wheat Chex', 'Wheaties', 'Wheaties Honey Gold']\n",
            "['name', '100% Bran', '100% Natural Bran', 'All-Bran', 'All-Bran with Extra Fiber', 'Almond Delight', 'Apple Cinnamon Cheerios', 'Apple Jacks', 'Basic 4']\n",
            "(78, 16)\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from io import StringIO\n",
        "file_path = \"./cereal.csv\"\n",
        "data = np.genfromtxt(\n",
        "                    file_path,delimiter=\",\",dtype=\"str\",autostrip=True\n",
        "                    \n",
        "                    )\n",
        "print(data)\n",
        "\n",
        "#les deux premi√®res lignes\n",
        "print(f\"Les deux premi√®res colonnes et toutes les lignes sont :{data[:,:2]}\")\n",
        "#la derni√®re colonne\n",
        "print(f\"la derni√®re colonne est  : {data[:,15]}\")\n",
        "#les deux premi√®res lignes de la quatri√®me colonne\n",
        "print(f\"Les deux premi√®res lignes de la 4√®me colonne : {data[:2,3]}\")\n",
        "\n",
        "#assignation des donn√©es de la colonne corn flakes\n",
        "corn_flakes = (data[:,0]=='Corn Flakes')\n",
        "corn_flakes_cals = data[corn_flakes,3]\n",
        "print(corn_flakes_cals)\n",
        "\n",
        "#assignation de la 3eme marque \n",
        "third_brand = (data[3,0])\n",
        "print(third_brand)\n",
        "\n",
        "#Mettre dans une liste toutes les marques\n",
        "data_tolist = data[:,0].tolist()\n",
        "print(data_tolist)\n",
        "\n",
        "#Mettre les dix premi√®res marques dans une liste\n",
        "first_ten_brands = data_tolist[0:9]\n",
        "print(first_ten_brands)\n",
        "\n",
        "print(data.shape) ## retourne (lignes, colonnes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BaW1VvWXCS7"
      },
      "source": [
        "#### Part 2\n",
        "\n",
        "* **Extraire** la premiere colonne du dataset et **la comparer** √† la valeur `'Special K'` Assigner le resultat √† une variable `special_k`\n",
        "* Executer la commande `print(data[special_k])`\n",
        "> bonus\n",
        "* Faire la meme chose mais le filtre verifie que le manufacturer est Quaker Oats (lire la doc du dataset üòâ)\n",
        "> bonus ¬≤\n",
        "* Print le nom des marques dont le fabricant est `Quaker Oats` et qui contiennent **moins** de `10 grammes` de sucre par portion\n",
        "* Ajouter une marque de c√©r√©ales \"healthy\" avec 0 grammes de sucre au dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuXFyhUepnMc",
        "outputId": "6ec9c05d-a76c-4d8f-8c48-6285d32b6953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Les special K sont : [['Special K' 'K' 'C' '110' '6' '0' '230' '1' '16' '3' '55' '25' '1' '1'\n",
            "  '1' '53.131324']]\n",
            "[['100% Natural Bran' 'Q' 'C' '120' '3' '5' '15' '2' '8' '8' '135' '0'\n",
            "  '3' '1' '1' '33.983679']\n",
            " [\"Cap'n'Crunch\" 'Q' 'C' '120' '1' '2' '220' '0' '12' '12' '35' '25' '2'\n",
            "  '1' '0.75' '18.042851']\n",
            " ['Honey Graham Ohs' 'Q' 'C' '120' '1' '2' '220' '1' '12' '11' '45' '25'\n",
            "  '2' '1' '1' '21.871292']\n",
            " ['Life' 'Q' 'C' '100' '4' '2' '150' '2' '12' '6' '95' '25' '2' '1'\n",
            "  '0.67' '45.328074']\n",
            " ['Puffed Rice' 'Q' 'C' '50' '1' '0' '0' '0' '13' '0' '15' '0' '3' '0.5'\n",
            "  '1' '60.756112']\n",
            " ['Puffed Wheat' 'Q' 'C' '50' '2' '0' '0' '1' '10' '0' '50' '0' '3' '0.5'\n",
            "  '1' '63.005645']\n",
            " ['Quaker Oat Squares' 'Q' 'C' '100' '4' '1' '135' '2' '14' '6' '110'\n",
            "  '25' '3' '1' '0.5' '49.511874']\n",
            " ['Quaker Oatmeal' 'Q' 'H' '100' '5' '2' '0' '2.7' '-1' '-1' '110' '0'\n",
            "  '1' '1' '0.67' '50.828392']]\n",
            "moins de 10 calories sont : [8, 6, 0, 0, 6, -1]\n",
            "le nom des marques dont le fabricant est Quaker Oats et qui contiennent moins de 10 grammes de sucres : [array(['Basic 4', 'Apple Cinnamon Cheerios', 'name', 'name',\n",
            "       'Apple Cinnamon Cheerios', 'Wheaties Honey Gold'], dtype='<U38')]\n"
          ]
        }
      ],
      "source": [
        "#Extraire la premiere colonne\n",
        "col1 = data[:,0]\n",
        "#assignation des donn√©es de la colonne special K\n",
        "special_k = (data[:,0]=='Special K')\n",
        "print(f\"Les special K sont : {data[special_k]}\")\n",
        "\n",
        "#le nom des marques dont le fabricant est Quaker Oats\n",
        "#avec le filtre manfacturer\n",
        "\n",
        "#ceux qui sont fabriqu√©s par quacker oats\n",
        "qo = (data[:,1] =='Q' )\n",
        "print(data[qo])\n",
        "#assignation du sucre de ceux qui ont √©t√© cr√©ees par quacker oats\n",
        "quacker_sugar = data[qo,9]\n",
        "#changement en type int\n",
        "quacker_oats = quacker_sugar.astype(int)\n",
        "#print(quacker_oats)\n",
        "#ceux qui ont moins de 10 calories\n",
        "quacker_10 = list(filter(lambda i : True if i < 10 else False,quacker_oats))\n",
        "print(f\"moins de 10 calories sont : {quacker_10}\")\n",
        "\n",
        "#afficher le nom des marques dont le fabricant est Quaker Oats et qui contiennent moins de 10 grammes de sucres\n",
        "\n",
        "marque = data[quacker_10,0]\n",
        "print(f\"le nom des marques dont le fabricant est Quaker Oats et qui contiennent moins de 10 grammes de sucres : {[marque]}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdsY64gl_0dw"
      },
      "source": [
        "#### Part 3\n",
        "\n",
        "Sur le m√™me dataset, √† l'aide d'une boucle `for`:\n",
        "\n",
        "\n",
        "*   Cr√©er un dictionnaire avec la moyenne de sucre par Fabricant de c√©rales\n",
        "*   Trouver la marque de c√©reales qui contient le plus de sucre par portion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjbTgYNbCaIj",
        "outputId": "5ab1f623-f8df-45f2-e82b-7031da73f3f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Les diff√©rente marques avec leurs moyennes de sucre est : {'Nabisco': 1.8333333333333333, 'Quaker Oats': 5.25, 'Kelloggs': 7.565217391304348, 'Ralston Purina': 6.125, 'Post': 8.777777777777779, 'General Mills': 7.954545454545454, 'American Home Food Products': 3.0}\n",
            "La marque de cr√©ales la plus sucr√©e est Post avec une moyenne de 8.777777777777779\n"
          ]
        }
      ],
      "source": [
        "marques = {\"Nabisco\":\"N\",\"Quaker Oats\":\"Q\",\"Kelloggs\":\"K\",\"Ralston Purina\":\"R\",\"Post\":\"P\",\"General Mills\":\"G\",\"American Home Food Products\":\"A\"}\n",
        "marque_sucre = {}\n",
        "for  i in marques:\n",
        "    marque_sucre[i]= np.mean((data[data[:,1]== marques[i]])[:,9].astype(float))\n",
        "print(f\"Les diff√©rente marques avec leurs moyennes de sucre est : {marque_sucre}\")\n",
        "ma = [\"Nabisco\",\"Quaker Oats\",\"Kelloggs\",\"Ralston Purina\",\"Post\",\"General Mills\",\"American Home Food Products\"]\n",
        "m = max([marque_sucre[i] for i in ma if i in ma])\n",
        "for i,j in marque_sucre.items() :\n",
        "    if j == m:\n",
        "        print(f\"La marque de cr√©ales la plus sucr√©e est {i} avec une moyenne de {j}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 367,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1wjqra3_yZo",
        "outputId": "ea12a660-30c6-45d0-e066-c7f4848eb455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Les diff√©rente marques avec leurs moyennes de sucre{'Nabisco': 1.8333333333333333, 'Quaker Oats': 5.25, 'Kelloggs': 7.565217391304348, 'Ralston Purina': 6.125, 'Post': 8.777777777777779, 'General Mills': 7.954545454545454, 'American Home Food Products': 3.0}\n",
            "La marque qui contiet le plus de sucres{'Nabisco': 1.8333333333333333, 'Quaker Oats': 5.25, 'Kelloggs': 7.565217391304348, 'Ralston Purina': 6.125, 'Post': 8.777777777777779, 'General Mills': 7.954545454545454, 'American Home Food Products': 3.0}\n"
          ]
        }
      ],
      "source": [
        "marques = {\"Nabisco\":\"N\",\"Quaker Oats\":\"Q\",\"Kelloggs\":\"K\",\"Ralston Purina\":\"R\",\"Post\":\"P\",\"General Mills\":\"G\",\"American Home Food Products\":\"A\"}\n",
        "marque_sucre = {}\n",
        "for  i in marques:\n",
        "    marque_sucre[i]= np.mean((data[data[:,1]== marques[i]])[:,9].astype(float))\n",
        "print(f\"Les diff√©rente marques avec leurs moyennes de sucre{marque_sucre}\")\n",
        "print(f\"La marque qui contiet le plus de sucres {marque_sucre}\")\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHsrGdy-5AZK"
      },
      "source": [
        "## EX03\n",
        "### Dataframes\n",
        "\n",
        "Refaire l'exo du TD 4 (fichier des series) en utilisant la librairie NumPy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 404,
      "metadata": {
        "id": "jIatRWhm5Xzo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from random import randint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "file_path = \"./netflix_titles.csv\"\n",
        "data = np.genfromtxt(\n",
        "                    file_path,delimiter=\",\",dtype=\"str\",autostrip=True\n",
        "                    \n",
        "                    )\n",
        "print(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Repartir sur une nouvelle branche\n",
        "git checkout main\n",
        "# Mettre √† jour notre branche locale\n",
        "git pull origin main\n",
        "# Recr√©er une branche pour le TD 05\n",
        "git checkout -b branch_name_td05\n",
        "# Dupliquer le fichier du td et rajouter en suffix son nom\n",
        "cd 'chemin/m1-miage/'\n",
        "cp 'src/to_do/td_05/td_05.ipynb' 'src/done/td_05/td_05_nom_prenom.ipynb'\n",
        "# Faire le travail necessaire sur votre fichier et commit et push\n",
        "git add 'src/done/td_05/td_05_nom_prenom.ipynb'\n",
        "git commit -m 'message descriptif du travail fait'\n",
        "git push --set-upstream origin nom_branche\n",
        "# Faire une pull request"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "597Hu82gSNCZ",
        "k2lJWv62kQZA",
        "94-12vgPXG10"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "41d2ab39d7a5795f1f406263962b60425c96c770e9c23d7560b7a64f7a85c300"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
